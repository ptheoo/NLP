ChatGPT said:
Lab3 â€” Word Embeddings (Lab Report)

Má»¥c tiÃªu: Thá»±c hiá»‡n cÃ¡c thao tÃ¡c vá»›i word embeddings: sá»­ dá»¥ng pretrained embedding (GloVe), huáº¥n luyá»‡n Word2Vec tá»« dá»¯ liá»‡u nhá» (Gensim) vÃ  lá»›n (Spark), táº¡o document embedding, giáº£m chiá»u & trá»±c quan hÃ³a, vÃ  phÃ¢n tÃ­ch káº¿t quáº£.
TÃ i liá»‡u nÃ y lÃ  Lab3.md Ä‘á»ƒ ná»™p/Ä‘Ã­nh kÃ¨m cÃ¹ng mÃ£ nguá»“n vÃ  file PDF (notebook) â€” chá»©a hÆ°á»›ng dáº«n cháº¡y, káº¿t quáº£ quan trá»ng, phÃ¢n tÃ­ch, nháº­n xÃ©t vÃ  cÃ¡c váº¥n Ä‘á»/giáº£i phÃ¡p.

Má»¥c lá»¥c

1. TÃ³m táº¯t tiáº¿n Ä‘á»™ (Checklist)

2. MÃ´i trÆ°á»ng & CÃ i Ä‘áº·t

3. HÆ°á»›ng dáº«n cháº¡y (How to run)

4. Ná»™i dung thá»±c thi & káº¿t quáº£ chÃ­nh (Outputs)

4.1 Spark Word2Vec demo (káº¿t quáº£)

4.2 Sá»­ dá»¥ng GloVe pretrained (lab4_test)

4.3 Huáº¥n luyá»‡n Word2Vec tá»« Ä‘áº§u (lab4_embedding_training_demo)

5. PhÃ¢n tÃ­ch & Nháº­n xÃ©t chi tiáº¿t (Pháº§n Quan trá»ng)

5.1 Pretrained GloVe â€” cháº¥t lÆ°á»£ng & nháº­n xÃ©t

5.2 Word2Vec tá»± huáº¥n luyá»‡n trÃªn en_ewt â€” vÃ¬ sao káº¿t quáº£ â€œká»³ láº¡â€?

5.3 So sÃ¡nh: Pretrained vs Trained-from-scratch

5.4 Giáº£m chiá»u & trá»±c quan hÃ³a â€” phÆ°Æ¡ng phÃ¡p vÃ  lá»i khuyÃªn

6. CÃ¡c váº¥n Ä‘á» gáº·p pháº£i & cÃ¡ch giáº£i quyáº¿t (Troubleshooting)

7. Äá» xuáº¥t cáº£i tiáº¿n & bÆ°á»›c tiáº¿p theo

8. TÃ i liá»‡u tham kháº£o & nguá»“n

1. TÃ³m táº¯t tiáº¿n Ä‘á»™ (Checklist)

Pháº§n 1: Triá»ƒn khai (50%)

 Task 1: Táº£i vÃ  sá»­ dá»¥ng pretrained model (Gensim) â€” glove-wiki-gigaword-50 (Ä‘Ã£ táº£i thÃ nh cÃ´ng).

 Láº¥y vector cá»§a má»™t tá»« (king) â€” OK.

 TÃ­nh similarity (king vs queen, king vs man) â€” OK.

 TÃ¬m cÃ¡c tá»« most_similar (computer) â€” OK.

 Task 2: NhÃºng cÃ¢u/vÄƒn báº£n báº±ng trung bÃ¬nh vector â€” OK.

 Task 3: Huáº¥n luyá»‡n model Word2Vec tá»« dá»¯ liá»‡u thÃ´ (en_ewt-ud-train.txt) â€” ÄÃ£ huáº¥n luyá»‡n thÃ nh cÃ´ng, model lÆ°u Ä‘Æ°á»£c.

 LÆ°u & táº£i láº¡i model huáº¥n luyá»‡n â€” OK.

 Task 4: Huáº¥n luyá»‡n model trÃªn táº­p dá»¯ liá»‡u lá»›n (Spark) â€” ÄÃ£ cháº¡y demo Spark Word2Vec (káº¿t quáº£ hiá»ƒn thá»‹).

 Task 5: Trá»±c quan hÃ³a embedding báº±ng PCA/t-SNE â€” (chÆ°a hoÃ n thÃ nh)

Pháº§n 2: BÃ¡o cÃ¡o vÃ  PhÃ¢n tÃ­ch (50%)

 Giáº£i thÃ­ch cÃ¡c bÆ°á»›c thá»±c hiá»‡n â€” cÃ³ trong bÃ¡o cÃ¡o nÃ y.

 HÆ°á»›ng dáº«n cháº¡y code â€” cÃ³.

 PhÃ¢n tÃ­ch káº¿t quáº£ â€” cÃ³ (má»¥c 5).

 Nháº­n xÃ©t vá» similarity / most_similar (pretrained) â€” cÃ³.

 PhÃ¢n tÃ­ch trá»±c quan hÃ³a â€” chÆ°a (do Task 5 chÆ°a lÃ m).

 So sÃ¡nh pretrained vs tá»± huáº¥n luyá»‡n â€” cÃ³.

 KhÃ³ khÄƒn & giáº£i phÃ¡p â€” cÃ³.

 TrÃ­ch dáº«n tÃ i liá»‡u â€” cÃ³.

TÃ³m táº¯t Ä‘iá»ƒm: hiá»‡n táº¡i báº¡n Ä‘Ã£ hoÃ n thÃ nh Ä‘a pháº§n pháº§n triá»ƒn khai (Spark, Gensim, pretrained) vÃ  phÃ¢n tÃ­ch vÄƒn báº£n â€” pháº§n trá»±c quan hÃ³a (PCA / t-SNE biá»ƒu Ä‘á»“) lÃ  pháº§n cÃ²n thiáº¿u Ä‘á»ƒ hoÃ n thiá»‡n 100%.

2. MÃ´i trÆ°á»ng & CÃ i Ä‘áº·t

Khuyáº¿n nghá»‹ mÃ´i trÆ°á»ng (venv):

Python 3.10

Virtual environment (vÃ­ dá»¥ venv) â€” báº¡n Ä‘ang dÃ¹ng (venv).

requirements.txt (gá»£i Ã½):

gensim
nltk
numpy==1.26.4
scipy==1.11.4
matplotlib
scikit-learn
pyspark


LÆ°u Ã½: Ä‘Ã£ tá»«ng gáº·p xung Ä‘á»™t numpy vs thinc â€” trong lab nÃ y phiÃªn báº£n numpy==1.26.4 + scipy==1.11.4 hoáº¡t Ä‘á»™ng á»•n vá»›i gensim. Náº¿u báº¡n cÃ i spacy/thinc cÃ³ thá»ƒ xuáº¥t cáº£nh bÃ¡o tÆ°Æ¡ng thÃ­ch â€” khÃ´ng gÃ¢y lá»—i cho cÃ¡c tÃ¡c vá»¥ hiá»‡n táº¡i.

NLTK: cáº§n download punkt Ä‘á»ƒ tokenize:

import nltk
nltk.download('punkt')

3. HÆ°á»›ng dáº«n cháº¡y (How to run)

KÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o:

# Windows PowerShell
.\venv\Scripts\Activate.ps1
# hoáº·c cmd:
.\venv\Scripts\activate.bat


CÃ i Ä‘áº·t dependencies:

pip install -r requirements.txt


Cháº¡y cÃ¡c script:

Spark Word2Vec demo:

python test/lab4_spark_word2vec_demo.py


Sá»­ dá»¥ng pretrained GloVe vÃ  test cÃ¡c hÃ m:

python test/lab4_test.py


Huáº¥n luyá»‡n Word2Vec tá»« en_ewt:

python test/lab4_embedding_training_demo.py


(TÃ¹y chá»n) Má»Ÿ notebook Lab3.ipynb, cháº¡y háº¿t cÃ¡c cell â†’ File â†’ Export as PDF Ä‘á»ƒ ná»™p.

4. Ná»™i dung thá»±c thi & káº¿t quáº£ chÃ­nh (Outputs)

DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c output báº¡n Ä‘Ã£ cháº¡y vÃ  copy vÃ o bÃ¡o cÃ¡o â€” giá»¯ nguyÃªn Ä‘á»ƒ giáº£ng viÃªn kiá»ƒm tra.

4.1 Spark Word2Vec demo (káº¿t quáº£)
Khá»Ÿi táº¡o SparkSession.
...
----------
Äá»c dá»¯ liá»‡u
Sá»‘ dÃ²ng Ä‘á»c Ä‘Æ°á»£c: 30000
----------
Tiá»n xá»­ lÃ½ vÄƒn báº£n vÃ  Tokenization
Sá»‘ dÃ²ng sau khi lá»c cÃ¡c dÃ²ng trá»‘ng: 30000
DataFrame sau khi Tokenization:
+--------------------------------------------------+
|                   words                          |
+--------------------------------------------------+
|[beginners, bbq, class, taking, place, in, miss...]|
...
only showing top 5 rows
----------
Huáº¥n luyá»‡n mÃ´ hÃ¬nh Word2Vec (Skip-gram)
25/10/15 00:29:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS

TÃ¬m cÃ¡c tá»« tÆ°Æ¡ng tá»± 'computer'
+----------+------------------+
|word      |similarity        |
+----------+------------------+
|desktop   |0.6939913630485535|
|computers |0.6567586064338684|
|software  |0.6353139281272888|
|coding    |0.6132869720458984|
|interfaces|0.6102142333984375|
|laptop    |0.6024858951568604|
|robohelp  |0.5980682373046875|
|backup    |0.5902743339538574|
|pc        |0.5899812579154968|
|graphical |0.5812470316886902|
+----------+------------------+

HoÃ n thÃ nh huáº¥n luyá»‡n Spark Word2Vec
...

4.2 Sá»­ dá»¥ng GloVe pretrained (lab4_test)
[nltk_data] Downloading package punkt...
ğŸ”¹ Äang táº£i mÃ´ hÃ¬nh 'glove-wiki-gigaword-50' ...
 MÃ´ hÃ¬nh 'glove-wiki-gigaword-50' táº£i thÃ nh cÃ´ng (50-dim).

--- ğŸ”¹ Láº¥y vector cá»§a tá»« 'king' ---
KÃ­ch thÆ°á»›c vector: (50,)
GiÃ¡ trá»‹ Ä‘áº§u tiÃªn: [ 0.50451   0.68607 -0.59517 -0.022801  0.60046 ]        

--- ğŸ”¹ Äá»™ tÆ°Æ¡ng Ä‘á»“ng ---
king vs queen: 0.78390425
king vs man: 0.53093773

--- ğŸ”¹ 10 tá»« gáº§n nghÄ©a vá»›i 'computer' ---
computers       -> 0.9165
software        -> 0.8815
technology      -> 0.8526
electronic      -> 0.8126
internet        -> 0.8060
computing       -> 0.8026
devices         -> 0.8016
digital         -> 0.7992
applications    -> 0.7913
pc              -> 0.7883

--- ğŸ”¹ Vector vÄƒn báº£n ---
Vector biá»ƒu diá»…n vÄƒn báº£n:
[ 0.04564168  0.36530998 -0.55974334  0.04014383  0.09655549  0.15623933
 -0.33622834 -0.12495166 -0.01031508 -0.5006717 ]
Äá»™ dÃ i vector: 50

4.3 Huáº¥n luyá»‡n Word2Vec tá»« Ä‘áº§u (lab4_embedding_training_demo) â€” káº¿t quáº£ sample
Báº®T Äáº¦U: HUáº¤N LUYá»†N MÃ” HÃŒNH WORD2VEC Tá»ª Äáº¦U
...
Tá»•ng sá»‘ cÃ¢u Ä‘Æ°á»£c Ä‘á»c Ä‘á»ƒ huáº¥n luyá»‡n: 14225
...
Word2Vec lifecycle event {... vocab=3866, vector_size=100 ...}
Huáº¥n luyá»‡n mÃ´ hÃ¬nh Word2Vec hoÃ n táº¥t.
KÃ­ch thÆ°á»›c tá»« vá»±ng mÃ´ hÃ¬nh (vocab size): 3866

3. Äang lÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n táº¡i: .../results/word2vec_ewt.model
LÆ°u mÃ´ hÃ¬nh thÃ nh cÃ´ng.

4. Demo sá»­ dá»¥ng mÃ´ hÃ¬nh Word2Vec Ä‘Ã£ huáº¥n luyá»‡n:

   A. 10 tá»« tÆ°Æ¡ng Ä‘á»“ng nháº¥t vá»›i 'student':
      1. science: 0.4967
      2. canada,: 0.4903
      3. buy: 0.4637
      ...
   B. Giáº£i quyáº¿t bÃ i toÃ¡n tÆ°Æ¡ng tá»±: king - man + woman = ?
      Káº¿t quáº£ (Top 3):
      1. arabia (Score: 0.4022)
      2. foot (Score: 0.3916)
      3. "it (Score: 0.3914)


Ghi chÃº: káº¿t quáº£ analogies sai lÃ  do háº¡n cháº¿ táº­p huáº¥n luyá»‡n (xem pháº§n phÃ¢n tÃ­ch).

5. PhÃ¢n tÃ­ch & Nháº­n xÃ©t chi tiáº¿t (Pháº§n Quan trá»ng)
5.1 Pretrained GloVe â€” cháº¥t lÆ°á»£ng & nháº­n xÃ©t

glove-wiki-gigaword-50 lÃ  embedding tiá»n huáº¥n luyá»‡n trÃªn corpora lá»›n (Wikipedia + Gigaword).

Káº¿t quáº£ king vs queen â‰ˆ 0.78 vÃ  most_similar cho computer Ä‘á»u ráº¥t há»£p lÃ½ â€” cho tháº¥y pretrained embeddings mang kiáº¿n thá»©c ngá»¯ nghÄ©a sÃ¢u rá»™ng.

Æ¯u Ä‘iá»ƒm: khÃ´ng cáº§n huáº¥n luyá»‡n, á»•n Ä‘á»‹nh, ráº¥t phÃ¹ há»£p cho bÃ i táº­p demo / baseline.

NhÆ°á»£c Ä‘iá»ƒm: khÃ´ng domain-specific; náº¿u dá»¯ liá»‡u cá»§a báº¡n khÃ¡c biá»‡t (vÃ­ dá»¥ vÄƒn báº£n y táº¿/tÃ i chÃ­nh), pretrained cÃ³ thá»ƒ khÃ´ng pháº£n Ã¡nh tá»‘t thuáº­t ngá»¯ chuyÃªn ngÃ nh.

5.2 Word2Vec tá»± huáº¥n luyá»‡n trÃªn en_ewt â€” vÃ¬ sao káº¿t quáº£ â€œká»³ láº¡â€?

Quan sÃ¡t: phÃ©p analogies king - man + woman cho káº¿t quáº£ nhÆ° arabia, foot, "it hoáº·c easily (trong má»™t láº§n khÃ¡c) â€” khÃ´ng pháº£i queen. NguyÃªn nhÃ¢n chÃ­nh:

Táº­p dá»¯ liá»‡u nhá» & háº¡n cháº¿ (14225 cÃ¢u, ~177k tá»«):

Má»™t sá»‘ tá»« quan trá»ng (king/queen) cÃ³ táº§n suáº¥t ráº¥t tháº¥p â†’ embedding bá»‹ noisy.

Vocab bá»‹ cáº¯t (effective_min_count=5):

Gensim Ä‘Ã£ loáº¡i bá» tá»« Ã­t xuáº¥t hiá»‡n, lÃ m máº¥t cÃ¡c tá»« cáº§n cho analogies.

Dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng/ngá»¯ cáº£nh nghÃ¨o:

Má»‘i quan há»‡ king â†” queen cáº§n nhiá»u ngá»¯ cáº£nh so sÃ¡nh (royalty contexts). Náº¿u khÃ´ng Ä‘á»§, mÃ´ hÃ¬nh khÃ´ng há»c Ä‘Æ°á»£c.

Thuáº­t toÃ¡n & siÃªu tham sá»‘: epochs, window, vector_size áº£nh hÆ°á»Ÿng máº¡nh. DÃ¹ Ä‘Ã£ láº·p nhiá»u epoch (á»Ÿ output báº¡n Ä‘Ã£ cháº¡y nhiá»u epoch), náº¿u dá»¯ liá»‡u thiáº¿u biá»ƒu diá»…n ngá»¯ cáº£nh thÃ¬ váº«n khÃ´ng tá»‘t.

Há»‡ quáº£: mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c má»‘i quan há»‡ cá»¥c bá»™/Ä‘á»“ng xuáº¥t hiá»‡n (co-occurrence) chá»© chÆ°a há»c Ä‘Æ°á»£c quy luáº­t ngá»¯ nghÄ©a sÃ¢u.

5.3 So sÃ¡nh: Pretrained vs Trained-from-scratch
TiÃªu chÃ­	Pretrained (GloVe)	Trained-from-scratch (EWT)
Dá»¯ liá»‡u huáº¥n luyá»‡n	Ráº¥t lá»›n	Nhá» (~17k cÃ¢u)
Cháº¥t lÆ°á»£ng analogies	Tá»‘t (kingâ†’queen)	KÃ©m / noisy
PhÃ¹ há»£p domain	Chung chung	CÃ³ thá»ƒ domain-specific (náº¿u corpus domain-specific)
Thá»i gian	Táº£i nhanh, khÃ´ng cáº§n train	Cáº§n thá»i gian train
Khi nÃ o dÃ¹ng	Baseline, nhanh	Khi cáº§n embedding chuyÃªn ngÃ nh

Káº¿t luáº­n: Vá»›i dá»¯ liá»‡u nhá», dÃ¹ng pretrained Ä‘á»ƒ lÃ m baseline; tá»± huáº¥n luyá»‡n chá»‰ thá»±c sá»± hiá»‡u quáº£ náº¿u cÃ³ corpus Ä‘á»§ lá»›n hoáº·c domain-specific.

5.4 Giáº£m chiá»u & trá»±c quan hÃ³a â€” phÆ°Æ¡ng phÃ¡p vÃ  lá»i khuyÃªn

PCA: nhanh, tuyáº¿n tÃ­nh â€” dÃ¹ng Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n tá»•ng quan.

t-SNE / UMAP: tÃ¡ch cá»¥m tá»‘t hÆ¡n, phÃ¹ há»£p cho visual analysis.

LÆ°u Ã½ thá»±c thi: chuyá»ƒn list vectors â†’ numpy.array trÆ°á»›c khi cho vÃ o t-SNE; chá»n perplexity phÃ¹ há»£p (5â€“50), thá»­ nhiá»u láº§n; chÃº Ã½ nhÃ£n hÆ¡i rá»‘i náº¿u váº½ quÃ¡ nhiá»u tá»« (chá»n 100â€“200 tá»« phá»• biáº¿n).

Viá»‡c chÆ°a lÃ m: trá»±c quan hÃ³a PCA/t-SNE hiá»‡n chÆ°a Ä‘Æ°á»£c thá»±c thi trong code cá»§a báº¡n â€” Ä‘á»ƒ hoÃ n thiá»‡n bÃ¡o cÃ¡o, cáº§n thÃªm cell cháº¡y PCA + t-SNE vÃ  chÃ¨n hÃ¬nh vÃ o PDF.

6. CÃ¡c váº¥n Ä‘á» gáº·p pháº£i & cÃ¡ch giáº£i quyáº¿t (Troubleshooting)
A. ImportError do SciPy / NumPy

Lá»—i: ImportError: cannot import name 'triu' from 'scipy.linalg'

Giáº£i phÃ¡p: háº¡ scipy vá» 1.11.4 vÃ  dÃ¹ng numpy==1.26.4. LÆ°u Ã½ xung Ä‘á»™t vá»›i thinc/spacy â€” náº¿u khÃ´ng dÃ¹ng spacy, cÃ³ thá»ƒ gá»¡ thinc/spacy hoáº·c bá» qua cáº£nh bÃ¡o.

B. ModuleNotFoundError: No module named 'src'

NguyÃªn nhÃ¢n: cháº¡y script tá»« thÆ° má»¥c con.

Giáº£i phÃ¡p:

Cháº¡y báº±ng: python -m test.lab4_test tá»« project root.

Hoáº·c thÃªm sys.path.append(...) trong script test Ä‘á»ƒ thÃªm thÆ° má»¥c gá»‘c vÃ o sys.path.

Hoáº·c táº¡o __init__.py phÃ¹ há»£p cho package.

C. t-SNE AttributeError: 'list' object has no attribute 'shape'

Giáº£i phÃ¡p: convert vectors_np = np.array(vectors) trÆ°á»›c khi gá»i tsne.fit_transform(vectors_np).

D. Káº¿t quáº£ analogieså (king â†’ easily)

NguyÃªn nhÃ¢n: dá»¯ liá»‡u nhá» / min_count loáº¡i bá» tá»« / thiáº¿u ngá»¯ cáº£nh.

Giáº£i phÃ¡p: dÃ¹ng corpus lá»›n hÆ¡n (text8, wikipedia) hoáº·c giáº£m min_count, tÄƒng epochs, tÄƒng window, hoáº·c dÃ¹ng pretrained.

7. Äá» xuáº¥t cáº£i tiáº¿n & bÆ°á»›c tiáº¿p theo

HoÃ n thiá»‡n pháº§n trá»±c quan hÃ³a (PCA + t-SNE/UMAP):

Chá»n ~200 tá»« phá»• biáº¿n, cháº¡y PCA vÃ  t-SNE, lÆ°u hÃ¬nh PNG vÃ o notebook/PDF.

So sÃ¡nh ká»¹ hÆ¡n pretrained vs trained-from-scratch:

Láº¥y má»™t sá»‘ cáº·p test (king-queen, paris-france, doctor-nurse) vÃ  Ä‘o cosine similarities trÃªn cáº£ hai model. Tá»•ng há»£p vÃ o báº£ng.

Thá»­ FastText: tá»‘t vá»›i tá»« hiáº¿m vÃ  OOV (subword).

TÄƒng/Ä‘á»•i tham sá»‘ huáº¥n luyá»‡n: giáº£m min_count, tÄƒng epochs (náº¿u dá»¯ liá»‡u Ä‘á»§), thá»­ window lá»›n hÆ¡n.

DÃ¹ng corpus lá»›n hÆ¡n: text8 (sáºµn cÃ³), Wikipedia (táº£i via gensim.downloader) â†’ huáº¥n luyá»‡n sáº½ cho analogies tá»‘t.

Äá»‹nh lÆ°á»£ng: ngoÃ i trá»±c quan, thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ Ä‘á»‹nh lÆ°á»£ng nhÆ° intrinsic evaluation (word similarity datasets) náº¿u cáº§